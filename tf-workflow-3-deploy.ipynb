{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2 Complete Project Workflow in Amazon SageMaker\n",
    "### Model Deployment\n",
    "    \n",
    "1. [Local Mode endpoint](#LocalModeEndpoint)\n",
    "2. [SageMaker hosted endpoint](#SageMakerHostedEndpoint)\n",
    "\n",
    "## Local Mode endpoint <a class=\"anchor\" id=\"LocalModeEndpoint\">\n",
    "\n",
    "While Amazon SageMakerâ€™s Local Mode training is very useful to make sure your training code is working before moving on to full scale training, it also would be useful to have a convenient way to test your model locally before incurring the time and expense of deploying it to production. One possibility is to fetch the TensorFlow SavedModel artifact or a model checkpoint saved in Amazon S3, and load it in your notebook for testing. However, an even easier way to do this is to use the SageMaker Python SDK to do this work for you by setting up a Local Mode endpoint.\n",
    "\n",
    "More specifically, the Estimator object from the Local Mode training job can be used to deploy a model locally. With one exception, this code is the same as the code you would use to deploy to production. In particular, all you need to do is invoke the local Estimator's deploy method, and similarly to Local Mode training, specify the instance type as either `local_gpu` or `local` depending on whether your notebook is on a GPU instance or CPU instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the variables stored from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following single line of code deploys the model locally in the SageMaker TensorFlow Serving container using the model artifacts from our local training job:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp0cm8kcm8_algo-1-09k9o_1\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:using default model name: model\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m model_config_list: {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   config: {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     name: \"model\",\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     base_path: \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m error_log  /dev/stderr error;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   default_type application/json;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     server localhost:8501;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     set $tfs_version 2.1.1;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     set $default_tfs_model model;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location /tfs {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location /ping {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         js_content ping_without_model;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location /invocations {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location ~ ^/models/(.*)/invoke {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location /models {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m TensorFlow ModelServer: 2.1.0-rc1+dev.sha.d80de10\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m TensorFlow Library: 2.1.1\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 11)\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m nginx version: nginx/1.18.0\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m built by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m built with OpenSSL 1.1.1  11 Sep 2018 (running with OpenSSL 1.1.1g  21 Apr 2020)\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.18.0/debian/debuild-base/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m INFO:__main__:started nginx (pid: 13)\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.598153: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.598837: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: model\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.697885: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.698613: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.698995: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.699379: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.699792: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.701631: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.702052: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.703240: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.732682: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.766438: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /opt/ml/model/1\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.771792: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 72001 microseconds.\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.772553: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.773054: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.773123: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.775075: I tensorflow_serving/model_servers/server.cc:362] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 2020-07-17 16:33:24.776094: I tensorflow_serving/model_servers/server.cc:382] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\u001b[36malgo-1-09k9o_1  |\u001b[0m 172.18.0.1 - - [17/Jul/2020:16:33:29 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\r\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data=local_model_data, role=role, framework_version='2.1')\n",
    "\n",
    "local_predictor = model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the Local Mode endpoint, simply invoke the Predictor's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-09k9o_1  |\u001b[0m 172.18.0.1 - - [17/Jul/2020:16:34:27 +0000] \"POST /invocations HTTP/1.1\" 200 167 \"-\" \"-\"\r\n"
     ]
    }
   ],
   "source": [
    "local_results = local_predictor.predict(x_test[:10])['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the predictions can be compared against the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \t[16.8 16.8 18.6 16.8 18.8 16.8 19.  19.7 18.5 16.8]\n",
      "target values: \t[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "local_preds_flat_list = [float('%.1f'%(item)) for sublist in local_results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(local_preds_flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only trained the model for a few epochs and there is much room for improvement, but the predictions so far should at least appear reasonably within the ballpark.  \n",
    "\n",
    "To avoid having the SageMaker TensorFlow Serving container indefinitely running locally, simply gracefully shut it down by calling the `delete_endpoint` method of the Predictor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "local_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SageMaker hosted endpoint <a class=\"anchor\" id=\"SageMakerHostedEndpoint\">\n",
    "\n",
    "Assuming the best model from the tuning job is better than the model produced by the individual Hosted Training job above, we could now easily deploy that model to production.  A convenient option is to use a SageMaker hosted endpoint, which serves real time predictions from the trained model (Batch Transform jobs also are available for asynchronous, offline predictions on large datasets). The endpoint will retrieve the TensorFlow SavedModel created during training and deploy it within a SageMaker TensorFlow Serving container. This all can be accomplished with one line of code.  \n",
    "\n",
    "More specifically, by calling the `deploy` method of the HyperparameterTuner object we instantiated above, we can directly deploy the best model from the tuning job to a SageMaker hosted endpoint.  It will take several minutes longer to deploy the model to the hosted endpoint compared to the Local Mode endpoint, which is more useful for fast prototyping of inference code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-17 16:26:22 Starting - Preparing the instances for training\n",
      "2020-07-17 16:26:22 Downloading - Downloading input data\n",
      "2020-07-17 16:26:22 Training - Training image download completed. Training in progress.\n",
      "2020-07-17 16:26:22 Uploading - Uploading generated training model\n",
      "2020-07-17 16:26:22 Completed - Training job completed\u001b[34m2020-07-17 16:26:08,910 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:08,911 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:08,916 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:08,924 sagemaker_tensorflow_container.training INFO     Appending the training job name to model_dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,186 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,186 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,194 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,198 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,208 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value val_loss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,212 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:09,220 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.tensorflow.estimator\",\n",
      "        \"sagemaker_estimator_class_name\": \"TensorFlow\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 74,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"epochs\": 14,\n",
      "        \"learning_rate\": 0.05226522618843149\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-2-workflow-17-16-19-47-003-4174bab3\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-512678715615/tf-2-workflow-17-16-19-47/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":74,\"epochs\":14,\"learning_rate\":0.05226522618843149,\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"TensorFlow\",\"sagemaker_estimator_module\":\"sagemaker.tensorflow.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-512678715615/tf-2-workflow-17-16-19-47/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"TensorFlow\",\"sagemaker_estimator_module\":\"sagemaker.tensorflow.estimator\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":74,\"epochs\":14,\"learning_rate\":0.05226522618843149,\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2-workflow-17-16-19-47-003-4174bab3\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-512678715615/tf-2-workflow-17-16-19-47/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"74\",\"--epochs\",\"14\",\"--learning_rate\",\"0.05226522618843149\",\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=74\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=14\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.05226522618843149\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --batch_size 74 --epochs 14 --learning_rate 0.05226522618843149 --model_dir /opt/ml/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mx train (404, 13) y train (404,)\u001b[0m\n",
      "\u001b[34mx test (102, 13) y test (102,)\u001b[0m\n",
      "\u001b[34m/cpu:0\u001b[0m\n",
      "\u001b[34mbatch_size = 74, epochs = 14, learning rate = 0.05226522618843149\u001b[0m\n",
      "\u001b[34mTrain on 404 samples, validate on 102 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 1s - loss: 631.3578#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 1ms/sample - loss: 276.5953 - val_loss: 54.8103\u001b[0m\n",
      "\u001b[34mEpoch 2/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 74.4473#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 37us/sample - loss: 53.9673 - val_loss: 38.4315\u001b[0m\n",
      "\u001b[34mEpoch 3/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 38.6087#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 44us/sample - loss: 37.7103 - val_loss: 34.7178\u001b[0m\n",
      "\u001b[34mEpoch 4/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 36.6888#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 42us/sample - loss: 41.5160 - val_loss: 33.3632\u001b[0m\n",
      "\u001b[34mEpoch 5/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 15.2867#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 28.1999 - val_loss: 33.2699\u001b[0m\n",
      "\u001b[34mEpoch 6/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 33.1069#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 49us/sample - loss: 26.5605 - val_loss: 28.2662\u001b[0m\n",
      "\u001b[34mEpoch 7/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 15.3530#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 21.4924 - val_loss: 28.7449\u001b[0m\n",
      "\u001b[34mEpoch 8/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 26.5511#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 38us/sample - loss: 23.2779 - val_loss: 23.2385\u001b[0m\n",
      "\u001b[34mEpoch 9/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 11.4226#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 16.0111 - val_loss: 60.0558\u001b[0m\n",
      "\u001b[34mEpoch 10/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 43.6301#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 35us/sample - loss: 28.0162 - val_loss: 19.8648\u001b[0m\n",
      "\u001b[34mEpoch 11/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 20.1347#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 16.3910 - val_loss: 18.0860\u001b[0m\n",
      "\u001b[34mEpoch 12/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 12.1996#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 13.8016 - val_loss: 22.3807\u001b[0m\n",
      "\u001b[34mEpoch 13/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 16.2188#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 36us/sample - loss: 13.6761 - val_loss: 26.1788\u001b[0m\n",
      "\u001b[34mEpoch 14/14\u001b[0m\n",
      "\u001b[34m#015 74/404 [====>.........................] - ETA: 0s - loss: 15.2524#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015404/404 [==============================] - 0s 34us/sample - loss: 13.8916 - val_loss: 21.6423\u001b[0m\n",
      "\u001b[34m102/102 - 0s - loss: 21.6423\n",
      "\u001b[0m\n",
      "\u001b[34mTest MSE : 21.642290414548388\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34m2020-07-17 16:26:12,339 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: tf-2-workflow-17-16-19-47-003-4174bab3\n"
     ]
    },
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit 'ml.m5.xlarge for endpoint usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d9de77ae7584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperparameterTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtuner_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtuner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuning_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtuning_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.t2.medium'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, wait, model_name, kms_key, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         )\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         )\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/serving.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             )\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m         self.sagemaker_client.create_endpoint(\n\u001b[0;32m-> 2415\u001b[0;31m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m         )\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit 'ml.m5.xlarge for endpoint usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "estimator = TensorFlow(**estimator_parameters)\n",
    "tuner_parameters['estimator'] = estimator\n",
    "\n",
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "tuner = tuner.attach(tuning_job_name)\n",
    "tuning_predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tuning_predictor.predict(x_test[:10])['predictions'] \n",
    "flat_list = [float('%.1f'%(item)) for sublist in results for item in sublist]\n",
    "print('predictions: \\t{}'.format(np.array(flat_list)))\n",
    "print('target values: \\t{}'.format(y_test[:10].round(decimals=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid billing charges from stray resources, you can delete the prediction endpoint to release its associated instance(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
